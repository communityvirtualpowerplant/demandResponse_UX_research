{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0515b5-9910-4c35-bccf-2d7062e3bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from scipy.integrate import trapezoid\n",
    "import math\n",
    "from statistics import mean\n",
    "from io import StringIO\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca0c67-a62e-48a9-af33-0a6dca5f3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)-8s [%(filename)s:%(lineno)d] %(message)s',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13523363-d47c-41e8-a313-4ba1f544ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_get_request(url:str='http://participant0.local:5000/',endpoint:str='',type:str='json',key=None,timeout=1):\n",
    "        \"\"\"Send GET request to the IP.\"\"\"\n",
    "        # get own data\n",
    "        max_tries = 3\n",
    "\n",
    "        if key:\n",
    "            headers = {\"Authorization\": f\"Bearer {key}\"}\n",
    "        else:\n",
    "            headers = {}\n",
    "            \n",
    "        for attempt in range(max_tries):\n",
    "            try:\n",
    "                response = requests.get(f\"{url}{endpoint}\",headers=headers, timeout=timeout)\n",
    "                response.raise_for_status()\n",
    "                if type == 'json':\n",
    "                    res= parse_datetimes(convert_bools(response.json()))\n",
    "                elif type == 'text':\n",
    "                    res= response.text\n",
    "                else:\n",
    "                    res= response.status_code\n",
    "                break\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                logging.error(f\"HTTP error occurred: {e}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f'{e}')\n",
    "                if attempt == max_tries-1: # try up to 3 times\n",
    "                    return None\n",
    "                else:\n",
    "                    logging.debug('SLEEEEEEEEEEEEEEEEEPING')\n",
    "                    await asyncio.sleep(1+attempt)\n",
    "        return res\n",
    "\n",
    "# # convert datetimes to iso formatted strings\n",
    "# def convert_datetimes(obj):\n",
    "#     if isinstance(obj, dict):\n",
    "#         return {k: convert_datetimes(v) for k, v in obj.items()}\n",
    "#     elif isinstance(obj, list):\n",
    "#         return [convert_datetimes(i) for i in obj]\n",
    "#     elif isinstance(obj, datetime):\n",
    "#         return obj.isoformat()\n",
    "#     else:\n",
    "#         return obj\n",
    "\n",
    "# convert to datetimes from iso formatted strings\n",
    "def parse_datetimes(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: parse_datetimes(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [parse_datetimes(i) for i in obj]\n",
    "    elif isinstance(obj, str):\n",
    "        try:\n",
    "            return datetime.fromisoformat(obj)\n",
    "        except ValueError:\n",
    "            return obj\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    " # Function to recursively convert \"true\"/\"false\" strings to Booleans\n",
    "def convert_bools(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_bools(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_bools(elem) for elem in obj]\n",
    "    elif obj == \"true\":\n",
    "        return True\n",
    "    elif obj == \"false\":\n",
    "        return False\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf93f93a-91a5-4ecb-a463-d375cd6b4ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG    [connectionpool.py:1049] Starting new HTTPS connection (1): api.airtable.com:443\n",
      "DEBUG    [connectionpool.py:544] https://api.airtable.com:443 \"GET /v0/apptjKq3GAr5CVOQT/events HTTP/1.1\" 200 436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.date(2025, 7, 28), datetime.date(2025, 8, 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get event log to filter out past events\n",
    "key='patr0QyMjRUmQManT.5731b23d71fa89b29c97d8be90faccf840ad8765bb8d88e66f583ad485f28e77'\n",
    "baseURL = 'https://api.airtable.com/v0/'\n",
    "base = 'apptjKq3GAr5CVOQT'\n",
    "table = 'events'\n",
    "\n",
    "res = await send_get_request(f'{baseURL}{base}/{table}',key=key)\n",
    "fields = []\n",
    "for r in res['records']:\n",
    "    fields.append(r['fields'])\n",
    "eventDF = pd.DataFrame(data=fields)\n",
    "\n",
    "# convert to date\n",
    "eventDF['date'] = pd.to_datetime(eventDF['date'])\n",
    "\n",
    "# drop unnecessary columns\n",
    "eventDF = eventDF.drop(columns=['modified','notes','network'])\n",
    "pastEventsDF=eventDF[eventDF['date']<datetime.now().replace(hour=0,minute=0,second=0,microsecond=0)]\n",
    "pastEventDates = [d.date() for d in list(pastEventsDF['date'])]\n",
    "pastEventDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3780db5f-863a-415f-97f5-2b9a9d0a0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getPastData():\n",
    "    # get file list\n",
    "    fileList = await send_get_request('http://participant0.local:5000/api/files?source=plugs',type='json')\n",
    "    logging.debug(f'all files: {fileList}')\n",
    "\n",
    "    filteredFileList = []\n",
    "    for f in fileList:\n",
    "        dStr = f.split('_')[1].replace('.csv','')\n",
    "        dDt = datetime.strptime(dStr, \"%Y-%m-%d\")\n",
    "        # get only dates within the last 30 days\n",
    "        if datetime.now() - dDt <= timedelta(days=30):            \n",
    "            filteredFileList.append(dDt)\n",
    "    logging.debug(f'filtered file list: {filteredFileList}')\n",
    "\n",
    "    data = []\n",
    "    for f in filteredFileList:\n",
    "        #filter out today's data\n",
    "        fToGet = f.strftime(\"%Y-%m-%d\")\n",
    "        if datetime.now().date().strftime(\"%Y-%m-%d\")  not in fToGet:    \n",
    "            r = await send_get_request(f'http://participant0.local:5000/api/data?source=plugs&date={fToGet}',type='text')\n",
    "            if type(r) == tuple: # the tuple includes the response code, which we don't care about\n",
    "                r = r[0]\n",
    "            data.append(r)\n",
    "\n",
    "    #parse response\n",
    "    parsedData = []\n",
    "    for d in data:\n",
    "        tempDF = pd.read_csv(StringIO(d), na_values=[\"\", \"NA\", \"NaN\", \"null\", \"NULL\"])\n",
    "        tempDF['datetime'] = pd.to_datetime(tempDF['datetime'])\n",
    "        cleanedTempDF = tempDF.dropna()\n",
    "        parsedData.append(cleanedTempDF)\n",
    "\n",
    "    return parsedData\n",
    "\n",
    "# get event windows\n",
    "def getEventWindows(data,eTime = 14):\n",
    "    eW = []\n",
    "    for d in data:\n",
    "        #get on timestamps between event start and end times\n",
    "        eW.append(d[[(d > d.replace(hour=eTime,minute=0,second=0,microsecond=0)) and (d <= d.replace(hour=eTime+4,minute=0,second=0,microsecond=0)) for d in d['datetime']]])\n",
    "    \n",
    "    return eW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d686b2c-0673-4ef1-881b-c9b7ca16d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/files?source=plugs HTTP/1.1\" 200 278\n",
      "DEBUG    [1552156714.py:4] all files: ['plugs_2025-07-22.csv', 'plugs_2025-07-24.csv', 'plugs_2025-07-25.csv', 'plugs_2025-07-26.csv', 'plugs_2025-07-27.csv', 'plugs_2025-07-28.csv', 'plugs_2025-07-29.csv', 'plugs_2025-07-30.csv', 'plugs_2025-07-31.csv', 'plugs_2025-08-01.csv', 'plugs_2025-08-02.csv', 'plugs_2025-08-03.csv']\n",
      "DEBUG    [1552156714.py:13] filtered file list: [datetime.datetime(2025, 7, 22, 0, 0), datetime.datetime(2025, 7, 24, 0, 0), datetime.datetime(2025, 7, 25, 0, 0), datetime.datetime(2025, 7, 26, 0, 0), datetime.datetime(2025, 7, 27, 0, 0), datetime.datetime(2025, 7, 28, 0, 0), datetime.datetime(2025, 7, 29, 0, 0), datetime.datetime(2025, 7, 30, 0, 0), datetime.datetime(2025, 7, 31, 0, 0), datetime.datetime(2025, 8, 1, 0, 0), datetime.datetime(2025, 8, 2, 0, 0), datetime.datetime(2025, 8, 3, 0, 0)]\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-22 HTTP/1.1\" 200 9891\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-24 HTTP/1.1\" 200 4663\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-25 HTTP/1.1\" 200 10189\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-26 HTTP/1.1\" 200 10494\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-27 HTTP/1.1\" 200 10421\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-28 HTTP/1.1\" 200 10935\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-29 HTTP/1.1\" 200 6265\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-30 HTTP/1.1\" 200 6410\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-07-31 HTTP/1.1\" 200 1143\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-08-01 HTTP/1.1\" 200 2309\n",
      "DEBUG    [connectionpool.py:241] Starting new HTTP connection (1): participant0.local:5000\n",
      "DEBUG    [connectionpool.py:544] http://participant0.local:5000 \"GET /api/data?source=plugs&date=2025-08-02 HTTP/1.1\" 200 10105\n"
     ]
    }
   ],
   "source": [
    "#get all past data for average seed value\n",
    "data = await getPastData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbac3ba8-c099-4198-af22-e3de0fa21f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event windows\n",
    "def listToDict(data):\n",
    "    rD = {}\n",
    "    for d in data:\n",
    "        if len(d)>0:\n",
    "            rD[d['datetime'].iloc[0].date().strftime(\"%Y-%m-%d\")]=d\n",
    "    \n",
    "    return rD\n",
    "\n",
    "# buckets df with datetime within an event window into hourly buckets\n",
    "# args: a dataframe with datetimes\n",
    "def hourlyBuckets(tempDF, tempStartTime:float, eventDuration:float=4) -> list[pd.DataFrame]:\n",
    "    hourlyPower = []\n",
    "    for h in range(eventDuration):\n",
    "        #print(tempDF['datetime'])\n",
    "        ts = tempStartTime + timedelta(hours=h)\n",
    "        te = tempStartTime + timedelta(hours=h + 1)\n",
    "        filteredTempDF = (tempDF[(tempDF['datetime']> ts) & (tempDF['datetime']<= te)]).copy() #data within the hour\n",
    "        #filteredTempDF = increments(filteredTempDF,ts)\n",
    "        hourlyPower.append(filteredTempDF)\n",
    "    return hourlyPower\n",
    "\n",
    "\n",
    "#args: a dataframe with datetime column\n",
    "# returns df with added increments column based on an hour\n",
    "def increments(df,fm=0)->pd.DataFrame:\n",
    "    if fm==0:\n",
    "        firstMeasurement = df['datetime'].min()\n",
    "    else:\n",
    "        firstMeasurement = fm\n",
    "\n",
    "    #print(firstMeasurement)\n",
    "    incList = []\n",
    "    for r in range(len(df['datetime'])):\n",
    "        incSec = (df['datetime'].iloc[r] - firstMeasurement).total_seconds()/60/60 #must convert back from seconds\n",
    "        incList.append(incSec)\n",
    "    df['increments'] = incList\n",
    "    return df\n",
    "\n",
    "#args: power and time increments (relative to the hour) for a given hour\n",
    "# returns the energy (Wh) for the hour\n",
    "def getWh(p:list[float],t:list[datetime])->float:\n",
    "    e = trapezoid(y=p, x=t)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe20f090-0cf2-4458-b1a7-98ee9da04daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowData = getEventWindows(data)\n",
    "#filter all data to event windows\n",
    "windowDict= listToDict(windowData)\n",
    "#windowDict\n",
    "\n",
    "# remove past events and weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8900cb-7959-4df1-80d2-6eb6584da2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowDictBuckets = {}\n",
    "eTime = 14\n",
    "for k,v in windowDict.items():\n",
    "    # create hourly buckets for each day\n",
    "    formattedStartTime = v['datetime'].iloc[0].replace(hour=eTime,minute=0,second=0,microsecond=0)\n",
    "    hourly = hourlyBuckets(v,formattedStartTime)\n",
    "\n",
    "    # add increments within each hour\n",
    "    incs = []\n",
    "    for i,h in enumerate(hourly):\n",
    "        # the increments function adds a column for the increment of a specific datapoint\n",
    "        incs.append(increments(h,formattedStartTime+timedelta(hours=i)))\n",
    "\n",
    "    hourlyEnergy = []\n",
    "    for inc in incs:\n",
    "        hourlyEnergy.append(getWh(inc['ac-W'],inc['increments']))\n",
    "        if (math.isnan(hourlyEnergy[-1])):\n",
    "            hourlyEnergy[-1] = 0.0\n",
    "\n",
    "    windowDictBuckets[k]=hourlyEnergy\n",
    "\n",
    "#windowDictBuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4eefb4-9a89-4839-8787-e0056277bdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(410.51729666666665)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakLoad = 0\n",
    "for k,v in windowDictBuckets.items():\n",
    "    for i,h in enumerate(v):\n",
    "        peakLoad = max(peakLoad,h)\n",
    "\n",
    "peakLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41faaaba-edc7-4fdd-80d7-ade9f3ae9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pastEventDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4488d89d-0151-4310-9ae7-b188665cc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = list(windowDictBuckets.keys())[0]\n",
    "# datetime.strptime(t, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e20544-d4a3-46e5-b393-c34183ffe488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2025, 7, 28), datetime.date(2025, 8, 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pastEventDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77351a0-71d9-4cdf-b1be-6d4414a1b6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2025, 7, 27), datetime.date(2025, 8, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pastEventPriorDates = [d - timedelta(days=1) for d in pastEventDates]\n",
    "pastEventPriorDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa13b4a-71c8-4f5e-b761-3be1315bbeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2025-07-22': [np.float64(327.08983430555554),\n",
       "  np.float64(56.76919861111111),\n",
       "  np.float64(56.718149861111094),\n",
       "  np.float64(205.02579972222225)],\n",
       " '2025-07-24': [np.float64(383.16116458333335),\n",
       "  np.float64(347.00701847222217),\n",
       "  np.float64(380.77539847222226),\n",
       "  np.float64(378.90866180555554)],\n",
       " '2025-07-25': [np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredBuckets = {}\n",
    "holidays =  ['2025-09-01']\n",
    "\n",
    "for k,v in windowDictBuckets.items():\n",
    "    kDT = datetime.strptime(k, \"%Y-%m-%d\")\n",
    "    #drop holidays\n",
    "    if not (k in holidays):\n",
    "        #drop DR event days\n",
    "        if not (kDT.date() in pastEventDates):\n",
    "            #drop DR event prior days\n",
    "            if not (kDT.date() in pastEventPriorDates):\n",
    "            # drop weekends\n",
    "                if kDT.weekday() <=4: # filter out weekends\n",
    "                    filteredBuckets[k]=v\n",
    "\n",
    "filteredBuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870dcaa3-8e7f-40f8-bf7f-98420b377d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkD = datetime.now().date() - timedelta(days=1)\n",
    "# checkD.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3f8a19-af01-4f19-9179-9380b138f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(filteredBuckets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6134d6f1-9a7d-4d8a-a7c8-bf0ea323552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "\n",
    "def tenDayCBL(b,p):\n",
    "    cblWindowAvg = {}\n",
    "    avgList = []\n",
    "\n",
    "    # loop backwards through dates\n",
    "    for d in range(1,31):\n",
    "        checkD = datetime.now().date() - timedelta(days=d)\n",
    "        checkDstr = checkD.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if checkDstr in list(b.keys()):\n",
    "            if mean(b[checkDstr])> p * .25:\n",
    "                if len(cblWindowAvg.keys()) == 0:\n",
    "                    p = mean(b[checkDstr])\n",
    "                else:\n",
    "                    avgList.append(mean(b[checkDstr]))\n",
    "                    p = mean(avgList)\n",
    "                cblWindowAvg[checkDstr]=mean(b[checkDstr])\n",
    "\n",
    "        if len(cblWindowAvg.keys()) >= 10:\n",
    "            break\n",
    "\n",
    "    # if not enough days, repeat without removing low days\n",
    "    if len(cblWindowAvg.keys()) < 10:\n",
    "        cblWindowAvg = {}\n",
    "        avgList = []\n",
    "        # loop backwards through dates\n",
    "        for d in range(1,31):\n",
    "            checkD = datetime.now().date() - timedelta(days=d)\n",
    "            checkDstr = checkD.strftime(\"%Y-%m-%d\")\n",
    "            if checkDstr in list(b.keys()):\n",
    "                cblWindowAvg[checkDstr]=mean(b[checkDstr])\n",
    "            if len(cblWindowAvg.keys()) >= 10:\n",
    "                break\n",
    "                \n",
    "    return cblWindowAvg\n",
    "\n",
    "tD = tenDayCBL(filteredBuckets,peakLoad)\n",
    "\n",
    "#get highest 5\n",
    "def fiveDayCBL(t):\n",
    "    allV = list(t.values())\n",
    "    allV.sort(reverse=True)\n",
    "\n",
    "    f = {}\n",
    "    for v in allV:\n",
    "        for k,vt in t.items():\n",
    "            if v == vt:\n",
    "                f[k]=v\n",
    "    return f\n",
    "\n",
    "CBLbasis = fiveDayCBL(tD)\n",
    "\n",
    "# hourlyAvg = [h / len(windowDictBuckets.keys()) for h in hourlySums]\n",
    "#  = hourlyAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5dd545-6966-4a88-bfa5-d87db8fa32dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(236.75033296296297),\n",
       " np.float64(134.5920723611111),\n",
       " np.float64(145.8311827777778),\n",
       " np.float64(194.64482050925926)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avgCBL(dates,buckets):\n",
    "    hourlyLists = [[],[],[],[]]\n",
    "    for d in dates:\n",
    "        hourlyLists[0].append(buckets[d][0])\n",
    "        hourlyLists[1].append(buckets[d][1])\n",
    "        hourlyLists[2].append(buckets[d][2])\n",
    "        hourlyLists[3].append(buckets[d][3])\n",
    "    hourlyAvg = []\n",
    "    for h in hourlyLists:\n",
    "        hourlyAvg.append(mean(h))\n",
    "\n",
    "    return hourlyAvg\n",
    "        \n",
    "avgCBL(list(CBLbasis.keys()), filteredBuckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cd3dee-3b1e-4b8b-9463-73213179dbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().time().hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6a7a949-f55d-4671-900f-7724db6d29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDict={\"csrp\":{\"baselineW\":0,\"baselineTS\":False,\"now\":False,\"upcoming\":False,\"avgPerf\":100},\n",
    "                    \"dlrp\":{\"baselineW\":0,\"now\":False,\"upcoming\":False,\"avgPerf\":100},\n",
    "                    \"datetime\":datetime.now(),\n",
    "                    \"eventPause\":{\"datetime\":datetime.now(), \"state\":False},\n",
    "                    \"relays\":{'bat-in':True,'bat-out':True,'ac':True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd417c91-0890-4bde-8421-3ef77837e02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "if not 'baselineTS' in stateDict.keys():\n",
    "    print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76ba2de-5ad7-48e9-9f5d-e0d575ba01f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "l = [4,4,3]\n",
    "for b,i in enumerate(l):\n",
    "    print(b)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9866114-3df3-47cd-8b94-93f94325c9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10-1)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20165d5-dd87-4091-8dfc-d37c9d5ebc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
